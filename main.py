import os
import sys
os.environ["KERAS_BACKEND"] = "torch"
import keras  # –ò—Å–ø–æ–ª—å–∑—É–µ–º Keras 3 —Å PyTorch Backend
import torch
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, Dataset
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
import time
import tkinter as tk
from tkinter import filedialog
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix

# –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ (CPU/GPU)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
emoji_of_videocard = "üî•üî•üî•" if torch.cuda.is_available() else "ü•îü•îü•î"
print(f"{emoji_of_videocard} {device} is using")

# –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–ª—è –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

class CatDataset(Dataset):
    """
    –ö–ª–∞—Å—Å –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å –∫–æ—Ç–∞–º–∏ –∏ –Ω–µ –∫–æ—Ç–∞–º–∏
    """
    def __init__(self, root_dir):
        """
        –û–∂–∏–¥–∞–µ—Ç—Å—è, —á—Ç–æ –≤ root_dir –Ω–∞—Ö–æ–¥—è—Ç—Å—è –¥–≤–µ –ø–∞–ø–∫–∏: 'cats' –∏ 'not_cats'
        """
        self.root_dir = root_dir
        self.image_paths = []
        self.labels = []
        # –ö–∞—Ç–µ–≥–æ—Ä–∏–∏: label 0 -> not_cats, label 1 -> cats
        for label, category in enumerate(["not_cats", "cats"]):
            category_dir = os.path.join(root_dir, category)
            for filename in os.listdir(category_dir):
                filepath = os.path.join(category_dir, filename)
                self.image_paths.append(filepath)
                self.labels.append(label)

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        img_path = self.image_paths[idx]
        label = self.labels[idx]
        image = Image.open(img_path).convert("RGB")
        image = transform(image)
        return image, torch.tensor(label, dtype=torch.float32)

def build_model(model_name: str) -> keras.Model:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–æ–¥–µ–ª—å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –µ–≥–æ –Ω–∞–∑–≤–∞–Ω–∏—è
    """
    inputs = keras.layers.Input(shape=(3, 224, 224))
    x = keras.layers.Permute((2, 3, 1))(inputs)

    if model_name == "MobileNet":
        base_model = keras.applications.MobileNet(input_shape=(224, 224, 3), include_top=False, input_tensor=x, weights="imagenet")
        dropout_rate = 0.2
        learning_rate = 0.001
        optimizer = keras.optimizers.Adam(learning_rate=learning_rate)

    elif model_name == "EfficientNetB0":
        base_model = keras.applications.EfficientNetB0(input_shape=(224, 224, 3), include_top=False, input_tensor=x, weights="imagenet")
        dropout_rate = 0.3
        learning_rate = 0.0005
        optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate)

    elif model_name == "DenseNet121":
        base_model = keras.applications.DenseNet121(input_shape=(224, 224, 3), include_top=False, input_tensor=x, weights="imagenet")
        dropout_rate = 0.5
        learning_rate = 0.0003
        optimizer = keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9)

    else:
        raise ValueError("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –º–æ–¥–µ–ª—å")

    base_model.trainable = False

    x = keras.layers.GlobalAveragePooling2D()(base_model.output)
    x = keras.layers.BatchNormalization()(x)
    x = keras.layers.Dropout(dropout_rate)(x)
    outputs = keras.layers.Dense(1, activation="sigmoid")(x)

    model = keras.Model(inputs, outputs, name=model_name)
    model.compile(optimizer=optimizer, loss="binary_crossentropy", metrics=["accuracy"])

    return model


def test_model(model: keras.Model, test_loader: DataLoader, filename) -> float:
    """
    –¢–µ—Å—Ç–∏—Ä—É–µ—Ç –º–æ–¥–µ–ª—å –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ –∏ –≤—ã–≤–æ–¥–∏—Ç –º–µ—Ç—Ä–∏–∫–∏
    """
    predictions = []
    true_labels = []
    
    model.eval()
    with torch.no_grad():
        for images, labels in test_loader:
            images = images.to(device)
            outputs = model.predict(images).flatten()
            preds = outputs  # –í model —É–∂–µ –µ—Å—Ç—å sigmoid
            predictions.extend(preds)
            true_labels.extend(labels.numpy().flatten())

    predictions_rounded = np.round(predictions)

    # üîπ –û—Ü–µ–Ω–∏–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
    accuracy = accuracy_score(true_labels, predictions_rounded)
    precision = precision_score(true_labels, predictions_rounded, zero_division=0)
    recall = recall_score(true_labels, predictions_rounded, zero_division=0)
    f1 = f1_score(true_labels, predictions_rounded, zero_division=0)
    roc_auc = roc_auc_score(true_labels, predictions)

    print(f"\n‚úÖ Test Accuracy: {accuracy:.4f}")
    print(f"üéØ Precision: {precision:.4f}")
    print(f"üîç Recall: {recall:.4f}")
    print(f"üìä F1-score: {f1:.4f}")
    print(f"üìà ROC-AUC: {roc_auc:.4f}")

    cm = confusion_matrix(true_labels, predictions_rounded)

    plt.figure(figsize=(5, 4))
    plt.imshow(cm, interpolation="nearest", cmap="Blues")
    plt.colorbar()
    tick_marks = np.arange(2)
    plt.xticks(tick_marks, ["Not Cat", "Cat"])
    plt.yticks(tick_marks, ["Not Cat", "Cat"])

    plt.xlabel("Predicted Label")
    plt.ylabel("True Label")
    plt.title("Confusion Matrix")

    # üîπ –ü–æ–¥–ø–∏—Å–∏ –∑–Ω–∞—á–µ–Ω–∏–π –≤–Ω—É—Ç—Ä–∏ —è—á–µ–µ–∫
    for i in range(2):
        for j in range(2):
            plt.text(j, i, cm[i, j], horizontalalignment="center", verticalalignment="center", color="black")

    plt.savefig(filename)

    return accuracy


def plot_hist(hist: keras.callbacks.History, filename):
    """
    –°—Ç—Ä–æ–∏—Ç –≥—Ä–∞—Ñ–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ (accuracy –∏ loss)
    """
    plt.plot(hist.history["accuracy"])
    plt.plot(hist.history["val_accuracy"])
    plt.title("model accuracy")
    plt.ylabel("accuracy")
    plt.xlabel("epoch")
    plt.legend(["train", "validation"], loc="upper left")
    plt.savefig(filename)

def create_gui(model: keras.Model):
    """
    GUI –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ —É–∂–µ –Ω–∞—Ç—Ä–µ–Ω–∏—Ä–æ–≤–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
    """
    def select_file():
        file_path = filedialog.askopenfilename(
            title="–í—ã–±–µ—Ä–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ",
            filetypes=[("Image Files", "*.png;*.jpg;*.jpeg")]
        )
        if file_path:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            img = Image.open(file_path).convert("RGB")
            img = transform(img).unsqueeze(0).to(device)
            start = time.time()
            with torch.no_grad():
                output = model.predict(img).item()
            elapsed = (time.time() - start) * 1000  # –≤—Ä–µ–º—è –≤ –º—Å
            probability = output * 100
            result_label.config(text=f"–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å (–∫–æ—Ç): {probability:.2f}%\n–í—Ä–µ–º—è: {elapsed:.2f} –º—Å")
    root = tk.Tk()
    root.title("Cat Detector GUI")
    root.geometry("400x200")
    btn = tk.Button(root, text="–í—ã–±—Ä–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", command=select_file, width=25, height=2)
    btn.pack(pady=20)
    result_label = tk.Label(root, text="–†–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ—è–≤–∏—Ç—Å—è –∑–¥–µ—Å—å", font=("Helvetica", 12))
    result_label.pack(pady=10)
    root.mainloop()

def get_data_loaders(model_name: str) -> tuple[DataLoader]:
    """
    –ì—Ä—É–∑–∏—Ç –¥–∞–Ω–Ω—ã–µ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç DataLoader –¥–ª—è –æ–±—É—á–µ–Ω–∏—è, –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    """
    # –ü—É—Ç–∏ –∫ –¥–∞–Ω–Ω—ã–º
    train_dir = "dataset/train"
    val_dir = "dataset/validation"
    test_dir = "dataset/test"
    
    # –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    batch_size_dict = {"MobileNet": 32, "EfficientNetB0": 16, "DenseNet121": 16}
    batch_size = batch_size_dict[model_name]

    # –°–æ–∑–¥–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç—ã
    train_dataset = CatDataset(train_dir)
    val_dataset = CatDataset(val_dir)
    test_dataset = CatDataset(test_dir)
    
    # DataLoader –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö –±–∞—Ç—á–∞–º–∏
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size)
    test_loader = DataLoader(test_dataset, batch_size=batch_size)

    return train_loader, val_loader, test_loader

class SaveEpochCallback(keras.callbacks.Callback):
    """
    Callback –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–π —ç–ø–æ—Ö–∏ —Å —É–∫–∞–∑–∞–Ω–∏–µ–º –Ω–æ–º–µ—Ä–∞ —ç–ø–æ—Ö–∏ –≤ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
    """
    def __init__(self, model_name):
        super().__init__()
        self.model_name = model_name
        
    def on_epoch_end(self, epoch, logs=None):
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–π —ç–ø–æ—Ö–∏
        filename = f"{self.model_name}_epoch_{epoch}.keras"
        self.model.save(filename)
        print(f"\n–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –∫–∞–∫ {filename}\n\n")

def train(model: keras.Model, epochs: int, train_loader: DataLoader, val_loader: DataLoader, callbacks):
    """
    –û–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è –∏ –∏—Å—Ç–æ—Ä–∏—é –æ–±—É—á–µ–Ω–∏—è
    """
    start_time = time.time()
    hist = model.fit(train_loader, epochs=epochs, validation_data=val_loader, callbacks=callbacks)
    training_time = time.time() - start_time
    
    return training_time, hist

if __name__ == '__main__':
    if len(sys.argv) < 2:
        print(f"main.py train <model> - –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏\nmain.py gui <model> - –¥–ª—è –∑–∞–ø—É—Å–∫–∞ GUI\nmain.py train_all - –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π")
        sys.exit(0)

    if 'train' in sys.argv[1]:
        if len(sys.argv) < 3 and 'train_all' != sys.argv[1]:
            print("–£–∫–∞–∂–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
            sys.exit(1)
        elif 'train_all' == sys.argv[1]:
            models = ["MobileNet", "EfficientNetB0", "DenseNet121"]
        else:
            models = [sys.argv[2]]
        
        for model_name in models:
            print(f"–û–±—É—á–∞—é –º–æ–¥–µ–ª—å {model_name}")
            
            epochs_dict = {"MobileNet": 15, "EfficientNetB0": 20, "DenseNet121": 25}
            epochs = epochs_dict[model_name]
            train_loader, val_loader, test_loader = get_data_loaders(model_name)
            print("–ó–∞–≥—Ä—É–∂–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ")


            # –î–æ–±–∞–≤–ª—è–µ–º callback –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
            best_model_callback = keras.callbacks.ModelCheckpoint(
                filepath="{epoch:03d}_{val_accuracy:03f}_"+f"{model_name}_best_version.keras",
                monitor='val_accuracy',
                save_best_only=True,
                mode='max',
                verbose=1
            )
            model = build_model(model_name)
            training_time, hist = train(model, epochs, train_loader, val_loader, callbacks=[SaveEpochCallback(model_name), best_model_callback])
            print(f"–í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è {model_name}: {training_time:.2f} —Å–µ–∫")

            plot_hist(hist, f"Accuracy_Loss_{model_name}_{epochs}.png")
        
            # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
            accuracy = test_model(model, test_loader, f"Test_Model_Function_{model_name}_{epochs}.png")
            print(f"–¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ: {accuracy:.4f}")

            model_filename = f"{model_name}.keras"
            model.save(model_filename)
            print(f"–£—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –º–æ–¥–µ–ª—å –≤ {model_filename}")
        
    elif 'gui' == sys.argv[1]:
        if len(sys.argv) < 3:
            print("–£–∫–∞–∂–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è GUI")
            sys.exit(1)

        model_name = sys.argv[2]
        is_started = False
        for model_filename in os.listdir("."):
            if 'best' in model_filename and model_name in model_filename:
                print(f'–ó–∞–ø—É—Å–∫–∞—é GUI —Å –º–æ–¥–µ–ª—å—é "{model_filename}"')
                is_started = True
                create_gui(keras.models.load_model(model_filename))
        if not is_started:
            print(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç {model_filename}")
        
    elif 'test' == sys.argv[1]:
        def analyze_folder(folder_path, threshold=70):
            results = []
            for filename in os.listdir(folder_path):
                if filename.lower().endswith(('.png', '.jpg', '.jpeg')):
                    file_path = os.path.join(folder_path, filename)
                    img = Image.open(file_path).convert("RGB")
                    img_tensor = transform(img).unsqueeze(0).to(device)
                    
                    with torch.no_grad():
                        output = model.predict(img_tensor).item()
                    
                    probability = output * 100
                    if probability > threshold:
                        results.append((file_path, probability))

            return results

        def display_results(results):
            num_images = len(results)
            cols = 3
            rows = (num_images + cols - 1) // cols

            fig, axes = plt.subplots(rows, cols, figsize=(15, 5*rows))
            fig.suptitle(f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é > 70%", fontsize=16)

            for i, (file_path, probability) in enumerate(results):
                img = Image.open(file_path)
                ax = axes[i//cols, i%cols] if rows > 1 else axes[i%cols]
                ax.imshow(img)
                ax.set_title(f"{os.path.basename(file_path)}\n–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å: {probability:.2f}%")
                ax.axis('off')

            # –°–∫—Ä—ã—Ç—å –ø—É—Å—Ç—ã–µ –ø–æ–¥–≥—Ä–∞—Ñ–∏–∫–∏
            for i in range(num_images, rows*cols):
                ax = axes[i//cols, i%cols] if rows > 1 else axes[i%cols]
                ax.axis('off')

            plt.tight_layout()
            plt.show()

        if len(sys.argv) < 3:
            print("–£–∫–∞–∂–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è GUI")
            sys.exit(1)

        model_name = sys.argv[2]
        # train_loader, val_loader, test_loader = get_data_loaders(model_name)
        # print("–ó–∞–≥—Ä—É–∂–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ")
        for model_filename in os.listdir("."):
            if 'best' in model_filename and model_name in model_filename:
                print(f'–ó–∞–ø—É—Å–∫–∞—é GUI —Å –º–æ–¥–µ–ª—å—é "{model_filename}"')
                break
        model = keras.models.load_model(model_filename)
        # accuracy = test_model(model, test_loader, f"Test_Model_Function_{model_name}.png")
        # print(f"–¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ: {accuracy:.4f}")

        # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–π
        folder_path = os.path.join("hand_validataion/nekogirls")
        results = analyze_folder(folder_path)
        display_results(results)
